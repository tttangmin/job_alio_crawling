{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잡알리오 공공기관 채용정보 내역 크롤링\n",
    "- ToDo : 잡알리오에서 원하는 공공기관(또는 상세검색)의 채용정보 내역을 크롤링\n",
    "- base url : https://job.alio.go.kr/recruit.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 채용정보 내역\n",
    "- 상세조건에 맞는 채용정보 리스트에서 각 공고별 링크 크롤링\n",
    "- 잡알리오의 채용정보 url 구조 : https://job.alio.go.kr/recruitview.do?idx=**[INDEX]**\n",
    "    - **[INDEX]** 에 해당하는 데이터를 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상세조건을 선택한 채용공고 리스트 url\n",
    "base_url = 'https://job.alio.go.kr/recruit.do?idx=274842&s_date=2019.05.01&e_date=2024.09.23&org_type=&org_name=C0459&search_type=&keyword=&order=REG_DATE&sort=DESC&pageSet=50&pageNo='\n",
    "idx_list=[]\n",
    "\n",
    "for i in range(1, 9): #페이지 수\n",
    "    list_url = base_url + str(i)    # 페이지별로 조회\n",
    "    response = requests.get(list_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    for href in soup.find('table', class_='tbl type_03').find('tbody').find_all('tr'):\n",
    "        temp = href.find('td', class_='left').find('a')['href']     # 각 채용공고 html에서 하이퍼링크 tag의 index 데이터 추출\n",
    "        idx_tag = re.findall(r\"'(.*?)'\", temp)\n",
    "        idx_list.append(idx_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 채용 상세정보 크롤링\n",
    "- 채용 상세정보 url : https://job.alio.go.kr/recruitview.do?idx=**[INDEX]**\n",
    "- 필요한 상세정보에 해당하는 tag 추출\n",
    "- 한 채용공고에 여러 직무가 있는 경우)\n",
    "    - 직무별로 상세정보를 나눠서 수집\n",
    "- 인원정보에 '명' 제외\n",
    "- 수집 데이터 : columns=['채용제목', '등록일', '채용인원', '응시자격', '직무', '응시인원', '선발인원']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_data = []\n",
    "job_base_url = \"https://job.alio.go.kr/recruitview.do?idx=\"     # 채용정보 상세정보 링크\n",
    "\n",
    "cnt = 1 #진행상황 체크용 건수 : 채용공고마다 건수 체크\n",
    "\n",
    "for idx in idx_list:\n",
    "    \n",
    "    job_url = job_base_url + idx[0]\n",
    "    job_response = requests.get(job_url)\n",
    "    job_soup = BeautifulSoup(job_response.content, 'html.parser')\n",
    "    \n",
    "    # 채용제목\n",
    "    title = job_soup.find('p')['title'].strip()\n",
    "    \n",
    "     # 등록일\n",
    "    date = job_soup.find('th', text='등록일').find_next('td').text.strip()\n",
    "    \n",
    "    # 채용인원\n",
    "    emp_num = re.findall(r\"(.*?)명\", job_soup.find('th', text='채용인원').find_next('td').text.strip())[0]\n",
    "    \n",
    "    # 응시자격\n",
    "    qualification = job_soup.find('h4', text='응시자격').find_next('p').get_text(separator='\\n')  \n",
    "    \n",
    "    # 한 공고에 여러 직무를 채용하는 경우 별개의 row로 수집\n",
    "    for t in job_soup.find('div', id='tab-2').find_all('table'):\n",
    "        \n",
    "        # 직무명\n",
    "        duty = t.find('th', class_='interviewName').text \n",
    "        \n",
    "        # 응시인원\n",
    "        enroll = t.find_all('td')[2].text.strip() \n",
    "        if '명' in enroll:\n",
    "            enroll = re.findall(r\"(.*?)명\", enroll)[0]  # 명 제외\n",
    "        elif enroll == '-':\n",
    "            enroll = 0\n",
    "        \n",
    "        # 최종인원\n",
    "        final = t.find_all('td')[5].text.strip() \n",
    "        if '명' in final:\n",
    "            final = re.findall(r\"(.*?)명\", final)[0] # 명 제외\n",
    "        elif final == '-':\n",
    "            final = 0\n",
    "        \n",
    "        details_data.append([title, date, emp_num, qualification, duty, enroll, final])\n",
    "        \n",
    "    cnt += 1\n",
    "    \n",
    "    # 진행상황 체크\n",
    "    if cnt % 10 == 1:\n",
    "        print('cnt: ', cnt, ' data_num', len(details_data))\n",
    "        print(details_data[-1])\n",
    "        print(job_url)\n",
    "\n",
    "df = pd.DataFrame(details_data, columns=['채용제목', '등록일', '채용인원', '응시자격', '직무', '응시인원', '선발인원'])\n",
    "\n",
    "# 현재 경로에 csv파일로 저장\n",
    "df.to_csv('job_alio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
